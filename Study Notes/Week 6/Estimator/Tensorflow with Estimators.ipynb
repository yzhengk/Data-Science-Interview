{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow with Estimators\n",
    "\n",
    "As we saw previously how to build a full Multi-Layer Perceptron model with full Sessions in Tensorflow. Unfortunately this was an extremely involved process. However developers have created Estimators that have an easier to use flow!\n",
    "\n",
    "It is much easier to use, but you sacrifice some level of customization of your model. Let's go ahead and explore it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Data\n",
    "\n",
    "We will the iris data set.\n",
    "\n",
    "Let's get the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('iris.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['sepal_length','sepal_width','petal_length','petal_width','target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('target',axis=1)\n",
    "y = df['target'].apply(int) # the target variable is defined as float here, it has to be integer, since it's classification problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "5      0\n",
       "6      0\n",
       "7      0\n",
       "8      0\n",
       "9      0\n",
       "10     0\n",
       "11     0\n",
       "12     0\n",
       "13     0\n",
       "14     0\n",
       "15     0\n",
       "16     0\n",
       "17     0\n",
       "18     0\n",
       "19     0\n",
       "20     0\n",
       "21     0\n",
       "22     0\n",
       "23     0\n",
       "24     0\n",
       "25     0\n",
       "26     0\n",
       "27     0\n",
       "28     0\n",
       "29     0\n",
       "      ..\n",
       "120    2\n",
       "121    2\n",
       "122    2\n",
       "123    2\n",
       "124    2\n",
       "125    2\n",
       "126    2\n",
       "127    2\n",
       "128    2\n",
       "129    2\n",
       "130    2\n",
       "131    2\n",
       "132    2\n",
       "133    2\n",
       "134    2\n",
       "135    2\n",
       "136    2\n",
       "137    2\n",
       "138    2\n",
       "139    2\n",
       "140    2\n",
       "141    2\n",
       "142    2\n",
       "143    2\n",
       "144    2\n",
       "145    2\n",
       "146    2\n",
       "147    2\n",
       "148    2\n",
       "149    2\n",
       "Name: target, Length: 150, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y # we need to shuffle the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimators\n",
    "\n",
    "Let's show you how to use the simpler Estimator interface!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Columns\n",
    "Let's create feature columns for tensorflow estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sepal_length', 'sepal_width', 'petal_length', 'petal_width'], dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-13-038c36f1496f>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-038c36f1496f>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    tf.feature_column.\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# after ., click\"tab\". It's going to show the different  functions.\n",
    "tf.feature_column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = []\n",
    "\n",
    "for col in X.columns:\n",
    "    feat_cols.append(tf.feature_column.numeric_column(col)) # .feature_column.numeric_column is the one you used for dealing\n",
    "    # with numerical columns. There's also special ways you can use for your categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[_NumericColumn(key='sepal_length', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='sepal_width', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='petal_length', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None),\n",
       " _NumericColumn(key='petal_width', shape=(1,), default_value=None, dtype=tf.float32, normalizer_fn=None)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow estimator inputs includes two major input, one for pandas one for numpy. So we use pandas here\n",
    "# training input functions\n",
    "# If you get the values include nan, so, that indicates you should set the batch_size smaller\n",
    "# num of epochs: when you've gone through all your training data one time. If I have gone through 5 times all the training data->\n",
    "# I have done with the TF estimator training \n",
    "# Shuffle is one you dealing with when the target values have been sorted. so can shuttle them around.\n",
    "input_func = tf.estimator.inputs.pandas_input_fn(x=X_train,y=y_train,batch_size=10,num_epochs=5,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/1s/fc5ymx_j00vdg383_t0__vk80000gn/T/tmp4rk_q28h\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/1s/fc5ymx_j00vdg383_t0__vk80000gn/T/tmp4rk_q28h', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x11220f668>, '_task_type': 'worker', '_task_id': 0, '_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# DNNClassifier: stands for deep neural network classifier.\n",
    "# hidden_units define how many layers, and how many neurons in that layer. First layer has 10 neurons, second layer has 20 neurons,\n",
    "# third layer has 10 neurons. These three are hidden layers. We also define how may classes we are expecting.\n",
    "classifier = tf.estimator.DNNClassifier(hidden_units=[10, 20, 10], n_classes=3,feature_columns=feat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/1s/fc5ymx_j00vdg383_t0__vk80000gn/T/tmp4rk_q28h/model.ckpt.\n",
      "INFO:tensorflow:loss = 21.775734, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 50 into /var/folders/1s/fc5ymx_j00vdg383_t0__vk80000gn/T/tmp4rk_q28h/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5.146884.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x11a1635f8>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Last step is to train the data\n",
    "classifier.train(input_fn=input_func,steps=50) # steps: how many steps you want to train for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "** Use the predict method from the classifier model to create predictions from X_test **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now use estimator test on our test dataset\n",
    "pred_fn = tf.estimator.inputs.pandas_input_fn(x=X_test,batch_size=len(X_test),shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /var/folders/1s/fc5ymx_j00vdg383_t0__vk80000gn/T/tmp4rk_q28h/model.ckpt-50\n"
     ]
    }
   ],
   "source": [
    "note_predictions = list(classifier.predict(input_fn=pred_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'class_ids': array([0]),\n",
       "  'classes': array([b'0'], dtype=object),\n",
       "  'logits': array([ 4.8443155, -0.7857063, -2.9842076], dtype=float32),\n",
       "  'probabilities': array([9.9602926e-01, 3.5742472e-03, 3.9663195e-04], dtype=float32)},\n",
       " {'class_ids': array([0]),\n",
       "  'classes': array([b'0'], dtype=object),\n",
       "  'logits': array([ 5.0409656, -0.8294249, -3.0936263], dtype=float32),\n",
       "  'probabilities': array([9.9689460e-01, 2.8130086e-03, 2.9230805e-04], dtype=float32)},\n",
       " {'class_ids': array([2]),\n",
       "  'classes': array([b'2'], dtype=object),\n",
       "  'logits': array([-3.3950083,  2.4074574,  2.7449396], dtype=float32),\n",
       "  'probabilities': array([0.00125605, 0.41589814, 0.5828458 ], dtype=float32)},\n",
       " {'class_ids': array([2]),\n",
       "  'classes': array([b'2'], dtype=object),\n",
       "  'logits': array([-3.434986 ,  2.3788385,  2.5214381], dtype=float32),\n",
       "  'probabilities': array([0.0013848 , 0.46376726, 0.5348479 ], dtype=float32)},\n",
       " {'class_ids': array([2]),\n",
       "  'classes': array([b'2'], dtype=object),\n",
       "  'logits': array([-3.6387484,  2.5295062,  2.9282374], dtype=float32),\n",
       "  'probabilities': array([0.00084064, 0.4012796 , 0.59787977], dtype=float32)},\n",
       " {'class_ids': array([2]),\n",
       "  'classes': array([b'2'], dtype=object),\n",
       "  'logits': array([-4.1858478,  2.8622131,  3.5127387], dtype=float32),\n",
       "  'probabilities': array([2.9789796e-04, 3.4276897e-01, 6.5693313e-01], dtype=float32)},\n",
       " {'class_ids': array([1]),\n",
       "  'classes': array([b'1'], dtype=object),\n",
       "  'logits': array([-2.205072 ,  1.652638 ,  0.3434913], dtype=float32),\n",
       "  'probabilities': array([0.01635444, 0.77449334, 0.20915224], dtype=float32)},\n",
       " {'class_ids': array([1]),\n",
       "  'classes': array([b'1'], dtype=object),\n",
       "  'logits': array([-2.6942225,  1.9837834,  1.5661286], dtype=float32),\n",
       "  'probabilities': array([0.00557444, 0.599561  , 0.39486462], dtype=float32)},\n",
       " {'class_ids': array([1]),\n",
       "  'classes': array([b'1'], dtype=object),\n",
       "  'logits': array([-2.507577  ,  1.8572336 ,  0.98940504], dtype=float32),\n",
       "  'probabilities': array([0.00887704, 0.6980416 , 0.2930813 ], dtype=float32)},\n",
       " {'class_ids': array([2]),\n",
       "  'classes': array([b'2'], dtype=object),\n",
       "  'logits': array([-4.122432 ,  2.8522234,  3.8958492], dtype=float32),\n",
       "  'probabilities': array([2.4353735e-04, 2.6038757e-01, 7.3936886e-01], dtype=float32)},\n",
       " {'class_ids': array([2]),\n",
       "  'classes': array([b'2'], dtype=object),\n",
       "  'logits': array([-3.4096713,  2.4342713,  2.7538712], dtype=float32),\n",
       "  'probabilities': array([0.00121766, 0.4202609 , 0.57852143], dtype=float32)},\n",
       " {'class_ids': array([1]),\n",
       "  'classes': array([b'1'], dtype=object),\n",
       "  'logits': array([-2.4441545 ,  1.800643  , -0.05469367], dtype=float32),\n",
       "  'probabilities': array([0.01224751, 0.8541614 , 0.13359107], dtype=float32)},\n",
       " {'class_ids': array([0]),\n",
       "  'classes': array([b'0'], dtype=object),\n",
       "  'logits': array([ 4.85011  , -0.7900338, -2.987715 ], dtype=float32),\n",
       "  'probabilities': array([9.9606860e-01, 3.5383916e-03, 3.9297526e-04], dtype=float32)},\n",
       " {'class_ids': array([1]),\n",
       "  'classes': array([b'1'], dtype=object),\n",
       "  'logits': array([-2.7820559,  2.052791 ,  1.5585917], dtype=float32),\n",
       "  'probabilities': array([0.00491216, 0.61804426, 0.37704355], dtype=float32)},\n",
       " {'class_ids': array([1]),\n",
       "  'classes': array([b'1'], dtype=object),\n",
       "  'logits': array([-3.0777502,  2.2326913,  1.9265984], dtype=float32),\n",
       "  'probabilities': array([0.00283688, 0.5742974 , 0.42286566], dtype=float32)},\n",
       " {'class_ids': array([0]),\n",
       "  'classes': array([b'0'], dtype=object),\n",
       "  'logits': array([ 3.600225  , -0.48337305, -2.5111556 ], dtype=float32),\n",
       "  'probabilities': array([0.98129237, 0.01653158, 0.002176  ], dtype=float32)},\n",
       " {'class_ids': array([1]),\n",
       "  'classes': array([b'1'], dtype=object),\n",
       "  'logits': array([-2.1571949 ,  1.6152681 ,  0.30917504], dtype=float32),\n",
       "  'probabilities': array([0.01777252, 0.7728742 , 0.20935328], dtype=float32)},\n",
       " {'class_ids': array([2]),\n",
       "  'classes': array([b'2'], dtype=object),\n",
       "  'logits': array([-3.1163588,  2.2404642,  2.856582 ], dtype=float32),\n",
       "  'probabilities': array([0.00165096, 0.350086  , 0.64826304], dtype=float32)},\n",
       " {'class_ids': array([0]),\n",
       "  'classes': array([b'0'], dtype=object),\n",
       "  'logits': array([ 4.3420134, -0.6885704, -2.6784766], dtype=float32),\n",
       "  'probabilities': array([9.9262637e-01, 6.4868070e-03, 8.8680035e-04], dtype=float32)},\n",
       " {'class_ids': array([1]),\n",
       "  'classes': array([b'1'], dtype=object),\n",
       "  'logits': array([-2.7524054,  2.020576 ,  1.1526128], dtype=float32),\n",
       "  'probabilities': array([0.00591988, 0.70015216, 0.29392788], dtype=float32)},\n",
       " {'class_ids': array([1]),\n",
       "  'classes': array([b'1'], dtype=object),\n",
       "  'logits': array([-2.4580314,  1.8250077,  0.5440903], dtype=float32),\n",
       "  'probabilities': array([0.01068507, 0.7742437 , 0.21507123], dtype=float32)},\n",
       " {'class_ids': array([1]),\n",
       "  'classes': array([b'1'], dtype=object),\n",
       "  'logits': array([-3.147953 ,  2.2354407,  1.557998 ], dtype=float32),\n",
       "  'probabilities': array([0.00303616, 0.66115427, 0.33580962], dtype=float32)},\n",
       " {'class_ids': array([0]),\n",
       "  'classes': array([b'0'], dtype=object),\n",
       "  'logits': array([ 5.115995  , -0.84673494, -3.1331463 ], dtype=float32),\n",
       "  'probabilities': array([9.9717367e-01, 2.5656067e-03, 2.6074387e-04], dtype=float32)},\n",
       " {'class_ids': array([1]),\n",
       "  'classes': array([b'1'], dtype=object),\n",
       "  'logits': array([-3.177648 ,  2.2393346,  2.0457246], dtype=float32),\n",
       "  'probabilities': array([0.00242861, 0.54692036, 0.45065102], dtype=float32)},\n",
       " {'class_ids': array([1]),\n",
       "  'classes': array([b'1'], dtype=object),\n",
       "  'logits': array([-2.8141599,  2.0823107,  1.7857143], dtype=float32),\n",
       "  'probabilities': array([0.00426824, 0.571162  , 0.42456982], dtype=float32)},\n",
       " {'class_ids': array([0]),\n",
       "  'classes': array([b'0'], dtype=object),\n",
       "  'logits': array([ 4.64286   , -0.74408615, -2.867186  ], dtype=float32),\n",
       "  'probabilities': array([9.9490261e-01, 4.5526004e-03, 5.4476480e-04], dtype=float32)},\n",
       " {'class_ids': array([0]),\n",
       "  'classes': array([b'0'], dtype=object),\n",
       "  'logits': array([ 4.511476 , -0.7331701, -2.7632473], dtype=float32),\n",
       "  'probabilities': array([9.9406683e-01, 5.2443868e-03, 6.8872125e-04], dtype=float32)},\n",
       " {'class_ids': array([2]),\n",
       "  'classes': array([b'2'], dtype=object),\n",
       "  'logits': array([-4.905438 ,  3.3314438,  4.945657 ], dtype=float32),\n",
       "  'probabilities': array([4.3940836e-05, 1.6599722e-01, 8.3395880e-01], dtype=float32)},\n",
       " {'class_ids': array([0]),\n",
       "  'classes': array([b'0'], dtype=object),\n",
       "  'logits': array([ 4.4007683 , -0.68706787, -2.7706513 ], dtype=float32),\n",
       "  'probabilities': array([9.9310827e-01, 6.1288276e-03, 7.6293689e-04], dtype=float32)},\n",
       " {'class_ids': array([2]),\n",
       "  'classes': array([b'2'], dtype=object),\n",
       "  'logits': array([-3.4018402,  2.3718958,  2.8411977], dtype=float32),\n",
       "  'probabilities': array([0.00119452, 0.38432184, 0.61448365], dtype=float32)},\n",
       " {'class_ids': array([1]),\n",
       "  'classes': array([b'1'], dtype=object),\n",
       "  'logits': array([-2.5975857,  1.9166368,  0.4966447], dtype=float32),\n",
       "  'probabilities': array([0.00874303, 0.7982961 , 0.19296087], dtype=float32)},\n",
       " {'class_ids': array([0]),\n",
       "  'classes': array([b'0'], dtype=object),\n",
       "  'logits': array([ 5.189729 , -0.8378394, -3.2382054], dtype=float32),\n",
       "  'probabilities': array([9.9737692e-01, 2.4050241e-03, 2.1809907e-04], dtype=float32)},\n",
       " {'class_ids': array([1]),\n",
       "  'classes': array([b'1'], dtype=object),\n",
       "  'logits': array([-2.2782426 ,  1.6948323 ,  0.32702282], dtype=float32),\n",
       "  'probabilities': array([0.01477486, 0.78525007, 0.19997507], dtype=float32)},\n",
       " {'class_ids': array([2]),\n",
       "  'classes': array([b'2'], dtype=object),\n",
       "  'logits': array([-4.64016  ,  3.1596246,  4.3807406], dtype=float32),\n",
       "  'probabilities': array([9.3324466e-05, 2.2771885e-01, 7.7218777e-01], dtype=float32)},\n",
       " {'class_ids': array([0]),\n",
       "  'classes': array([b'0'], dtype=object),\n",
       "  'logits': array([ 4.7518325, -0.7335286, -3.0750158], dtype=float32),\n",
       "  'probabilities': array([9.9547464e-01, 4.1282703e-03, 3.9707570e-04], dtype=float32)},\n",
       " {'class_ids': array([0]),\n",
       "  'classes': array([b'0'], dtype=object),\n",
       "  'logits': array([ 5.632419 , -0.9345958, -3.4762807], dtype=float32),\n",
       "  'probabilities': array([9.9848562e-01, 1.4038591e-03, 1.1053091e-04], dtype=float32)},\n",
       " {'class_ids': array([2]),\n",
       "  'classes': array([b'2'], dtype=object),\n",
       "  'logits': array([-3.8332694,  2.6901097,  3.499381 ], dtype=float32),\n",
       "  'probabilities': array([4.5222169e-04, 3.0790648e-01, 6.9164127e-01], dtype=float32)},\n",
       " {'class_ids': array([2]),\n",
       "  'classes': array([b'2'], dtype=object),\n",
       "  'logits': array([-4.5331964,  3.1533127,  3.9407372], dtype=float32),\n",
       "  'probabilities': array([1.4351169e-04, 3.1267703e-01, 6.8717939e-01], dtype=float32)},\n",
       " {'class_ids': array([0]),\n",
       "  'classes': array([b'0'], dtype=object),\n",
       "  'logits': array([ 4.2799044 , -0.67709726, -2.647254  ], dtype=float32),\n",
       "  'probabilities': array([9.9204904e-01, 6.9780597e-03, 9.7298576e-04], dtype=float32)},\n",
       " {'class_ids': array([1]),\n",
       "  'classes': array([b'1'], dtype=object),\n",
       "  'logits': array([-2.7613678,  2.0037308,  0.6818994], dtype=float32),\n",
       "  'probabilities': array([0.00668308, 0.7842101 , 0.2091069 ], dtype=float32)},\n",
       " {'class_ids': array([2]),\n",
       "  'classes': array([b'2'], dtype=object),\n",
       "  'logits': array([-3.4126606,  2.4134593,  2.9243548], dtype=float32),\n",
       "  'probabilities': array([0.00110479, 0.3745693 , 0.6243258 ], dtype=float32)},\n",
       " {'class_ids': array([2]),\n",
       "  'classes': array([b'2'], dtype=object),\n",
       "  'logits': array([-3.9692807,  2.7431397,  3.650879 ], dtype=float32),\n",
       "  'probabilities': array([3.4935147e-04, 2.8736228e-01, 7.1228838e-01], dtype=float32)},\n",
       " {'class_ids': array([1]),\n",
       "  'classes': array([b'1'], dtype=object),\n",
       "  'logits': array([-3.4278517,  2.375555 ,  1.8554149], dtype=float32),\n",
       "  'probabilities': array([0.00188879, 0.6259959 , 0.37211525], dtype=float32)},\n",
       " {'class_ids': array([1]),\n",
       "  'classes': array([b'1'], dtype=object),\n",
       "  'logits': array([-2.8177238,  2.0606518,  1.4051203], dtype=float32),\n",
       "  'probabilities': array([0.00498395, 0.6549752 , 0.34004086], dtype=float32)},\n",
       " {'class_ids': array([1]),\n",
       "  'classes': array([b'1'], dtype=object),\n",
       "  'logits': array([-2.7458742,  2.0027905,  1.1810739], dtype=float32),\n",
       "  'probabilities': array([0.00598151, 0.69044584, 0.30357265], dtype=float32)}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "note_predictions # probabilities is the probability for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'class_ids': array([0]),\n",
       " 'classes': array([b'0'], dtype=object),\n",
       " 'logits': array([ 4.8443155, -0.7857063, -2.9842076], dtype=float32),\n",
       " 'probabilities': array([9.9602926e-01, 3.5742472e-03, 3.9663195e-04], dtype=float32)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "note_predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "note_predictions[0]['class_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_preds  = []\n",
    "for pred in note_predictions:\n",
    "    final_preds.append(pred['class_ids'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Now create a classification report and a Confusion Matrix. Does anything stand out to you?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[13  0  0]\n",
      " [ 0 17  1]\n",
      " [ 0  1 13]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,final_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        13\n",
      "          1       0.94      0.94      0.94        18\n",
      "          2       0.93      0.93      0.93        14\n",
      "\n",
      "avg / total       0.96      0.96      0.96        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,final_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Job!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1. EDA -> Done\n",
    "2. M5 Proj ->\n",
    "3. Capston Proj -> into ur resume\n",
    "\n",
    "POC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
